{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>valeur</th>\n",
       "      <th>qualificatif</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>35.409255</td>\n",
       "      <td>Bon</td>\n",
       "      <td>291.608974</td>\n",
       "      <td>79.324786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>23.512584</td>\n",
       "      <td>Bon</td>\n",
       "      <td>289.831760</td>\n",
       "      <td>75.349785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>34.669224</td>\n",
       "      <td>Bon</td>\n",
       "      <td>288.229605</td>\n",
       "      <td>72.039474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>21.981365</td>\n",
       "      <td>Bon</td>\n",
       "      <td>289.450428</td>\n",
       "      <td>77.387580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-05</td>\n",
       "      <td>21.669476</td>\n",
       "      <td>Bon</td>\n",
       "      <td>290.004077</td>\n",
       "      <td>78.336910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>19.411680</td>\n",
       "      <td>Très bon</td>\n",
       "      <td>286.051875</td>\n",
       "      <td>84.543750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>15.648780</td>\n",
       "      <td>Très bon</td>\n",
       "      <td>284.314968</td>\n",
       "      <td>82.893843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>29.964674</td>\n",
       "      <td>Bon</td>\n",
       "      <td>281.876160</td>\n",
       "      <td>84.588608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>59.634476</td>\n",
       "      <td>Moyen</td>\n",
       "      <td>282.037917</td>\n",
       "      <td>83.122917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>88.705232</td>\n",
       "      <td>Médiocre</td>\n",
       "      <td>282.293724</td>\n",
       "      <td>84.625523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date     valeur qualificatif  temperature   humidity\n",
       "0   2019-10-01  35.409255          Bon   291.608974  79.324786\n",
       "1   2019-10-02  23.512584          Bon   289.831760  75.349785\n",
       "2   2019-10-03  34.669224          Bon   288.229605  72.039474\n",
       "3   2019-10-04  21.981365          Bon   289.450428  77.387580\n",
       "4   2019-10-05  21.669476          Bon   290.004077  78.336910\n",
       "..         ...        ...          ...          ...        ...\n",
       "87  2019-12-27  19.411680     Très bon   286.051875  84.543750\n",
       "88  2019-12-28  15.648780     Très bon   284.314968  82.893843\n",
       "89  2019-12-29  29.964674          Bon   281.876160  84.588608\n",
       "90  2019-12-30  59.634476        Moyen   282.037917  83.122917\n",
       "91  2019-12-31  88.705232     Médiocre   282.293724  84.625523\n",
       "\n",
       "[92 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/preprocess-data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Seperate dataset to feature & label set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 35.40925545 291.60897436  79.32478632]\n",
      " [ 23.51258405 289.83175966  75.34978541]\n",
      " [ 34.66922426 288.22960526  72.03947368]\n",
      " [ 21.98136459 289.45042827  77.3875803 ]\n",
      " [ 21.66947578 290.00407725  78.33690987]\n",
      " [ 23.43752597 289.65851528  78.27510917]\n",
      " [ 26.11668443 288.76184211  76.96052632]\n",
      " [ 24.67594973 290.13169935  77.32026144]\n",
      " [ 16.96153542 289.00032258  78.98924731]\n",
      " [ 22.18934812 289.25343348  75.33261803]\n",
      " [ 33.76499921 290.07441113  75.93147752]\n",
      " [ 30.51595275 291.33678038  79.78464819]\n",
      " [ 37.75002993 292.53400853  76.47334755]\n",
      " [ 37.16592586 291.41559829  78.93589744]\n",
      " [ 26.57727126 289.1395966   80.06581741]\n",
      " [ 21.12705143 288.94658849  78.44776119]\n",
      " [ 30.75551601 289.24765458  81.03624733]\n",
      " [ 28.30384926 289.23571429  81.60554371]\n",
      " [ 40.37571383 289.3517094   83.78632479]\n",
      " [ 39.92010781 289.2264454   83.85867238]\n",
      " [ 16.90840675 288.10053533  84.19914347]\n",
      " [ 12.6931172  287.81072187  85.25053079]\n",
      " [ 23.57408326 289.12840173  83.50323974]\n",
      " [ 29.53141209 288.94542484  82.44662309]\n",
      " [ 23.26119136 289.43282609  81.3673913 ]\n",
      " [ 22.12771056 289.62811159  78.5472103 ]\n",
      " [ 34.24630483 288.66800847  79.73516949]\n",
      " [ 29.34030798 288.11659619  83.41860465]\n",
      " [ 21.1547572  288.09270613  83.78858351]\n",
      " [ 17.80267018 288.08263158  86.09894737]\n",
      " [ 26.10776047 288.44536842  85.93684211]\n",
      " [ 23.27136052 288.84449153  87.6440678 ]\n",
      " [ 22.40891895 288.90286624  83.94692144]\n",
      " [ 34.75334466 287.85489362  82.66808511]\n",
      " [ 16.85749177 288.0806867   80.66309013]\n",
      " [ 18.93400647 286.69851695  81.62288136]\n",
      " [ 19.42060421 286.23398268  82.03679654]\n",
      " [ 15.93984619 285.24134199  80.05844156]\n",
      " [ 20.07122288 284.41468085  82.60425532]\n",
      " [ 20.86158102 284.42052632  81.09473684]\n",
      " [ 21.56024379 284.13432203  80.32627119]\n",
      " [ 24.24818784 284.49038462  80.61752137]\n",
      " [ 22.96369156 284.67943633  78.55532359]\n",
      " [ 23.4192284  284.3793501   79.09433962]\n",
      " [ 22.10595409 283.59829876  82.84854772]\n",
      " [ 19.21756691 282.97334711  85.3285124 ]\n",
      " [ 30.21973274 283.43309278  83.53814433]\n",
      " [ 42.3192339  283.3408142   83.20041754]\n",
      " [ 39.70371917 283.53807531  82.4623431 ]\n",
      " [ 19.2059796  283.65186722  81.7033195 ]\n",
      " [ 49.65770062 282.87262156  83.70824524]\n",
      " [ 44.66858646 284.09192872  84.95387841]\n",
      " [ 19.09128255 285.56212766  82.04893617]\n",
      " [ 19.32877047 286.49853556  84.87656904]\n",
      " [ 21.56439446 285.66746362  85.57380457]\n",
      " [ 38.0109     286.57196653  86.11087866]\n",
      " [ 50.46275908 287.44578947  84.22736842]\n",
      " [ 27.87013807 287.60801688  82.01054852]\n",
      " [ 26.94391442 287.12148847  81.22641509]\n",
      " [ 26.33521759 286.35414938  82.21576763]\n",
      " [ 21.46619636 284.51991701  83.75311203]\n",
      " [ 12.09047344 284.38752621  84.66666667]\n",
      " [ 18.51544525 283.40220126  81.83438155]\n",
      " [ 35.72968774 282.29875     83.11458333]\n",
      " [ 92.23164776 282.21041667  82.52291667]\n",
      " [ 94.85148611 282.57448133  82.17219917]\n",
      " [ 92.0686299  284.10373444  83.98340249]\n",
      " [ 87.529968   285.85964361  83.51781971]\n",
      " [ 40.90316115 286.28924843  81.67640919]\n",
      " [ 26.74841752 285.68112033  76.53941909]\n",
      " [ 29.07843483 283.96410256  77.72008547]\n",
      " [ 35.50786862 283.8123431   80.4539749 ]\n",
      " [ 29.38319832 283.86854167  82.33541667]\n",
      " [ 28.57291692 285.66549894  80.10615711]\n",
      " [ 25.89261703 286.93616352  78.4129979 ]\n",
      " [ 21.43492792 286.86055901  80.64596273]\n",
      " [ 29.8894426  286.95981211  83.36743215]\n",
      " [ 33.23142963 287.56416667  79.49375   ]\n",
      " [ 56.63595772 286.91923077  83.14968815]\n",
      " [ 30.16629277 288.09173554  78.52892562]\n",
      " [ 30.57309374 287.170625    81.92916667]\n",
      " [ 23.68155121 286.27004132  82.65702479]\n",
      " [ 28.54607587 286.40729167  78.17291667]\n",
      " [ 30.10254529 285.96046025  77.12343096]\n",
      " [ 26.72894392 287.254       80.21684211]\n",
      " [ 26.83838345 285.92044025  81.19916143]\n",
      " [ 30.41021425 285.03958333  82.23958333]\n",
      " [ 19.41168025 286.051875    84.54375   ]\n",
      " [ 15.64877994 284.31496815  82.89384289]\n",
      " [ 29.96467362 281.87616034  84.58860759]\n",
      " [ 59.63447621 282.03791667  83.12291667]\n",
      " [ 88.70523229 282.29372385  84.62552301]]\n",
      "['Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Très bon' 'Bon' 'Bon'\n",
      " 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Très bon'\n",
      " 'Très bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Très bon' 'Bon'\n",
      " 'Bon' 'Bon' 'Bon' 'Très bon' 'Très bon' 'Très bon' 'Très bon' 'Bon' 'Bon'\n",
      " 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Très bon' 'Bon' 'Bon' 'Bon' 'Très bon'\n",
      " 'Bon' 'Bon' 'Très bon' 'Très bon' 'Bon' 'Bon' 'Moyen' 'Bon' 'Bon' 'Bon'\n",
      " 'Bon' 'Très bon' 'Très bon' 'Bon' 'Mauvais' 'Mauvais' 'Mauvais'\n",
      " 'Médiocre' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon'\n",
      " 'Moyen' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Bon' 'Très bon'\n",
      " 'Très bon' 'Bon' 'Moyen' 'Médiocre']\n"
     ]
    }
   ],
   "source": [
    "Y = df.values[:,2]\n",
    "dfX = df.drop(['qualificatif', 'date'], axis=1)\n",
    "X = dfX.values\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = preprocessing.LabelEncoder()\n",
    "# Yle = le.fit_transform(Y)\n",
    "# Yle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Seperate training & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X,Y,test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Normalize feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xss_train = ss.fit_transform(X_train)\n",
    "Xss_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Import classification libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Find best parameters for classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_param = {'random_state': range(20)}\n",
    "knn_param = {'n_neighbors': range(1, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'random_state': 0}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "1.000 (+/-0.000) for {'random_state': 0}\n",
      "1.000 (+/-0.000) for {'random_state': 1}\n",
      "1.000 (+/-0.000) for {'random_state': 2}\n",
      "0.969 (+/-0.071) for {'random_state': 3}\n",
      "0.969 (+/-0.071) for {'random_state': 4}\n",
      "0.969 (+/-0.071) for {'random_state': 5}\n",
      "1.000 (+/-0.000) for {'random_state': 6}\n",
      "1.000 (+/-0.000) for {'random_state': 7}\n",
      "1.000 (+/-0.000) for {'random_state': 8}\n",
      "0.984 (+/-0.059) for {'random_state': 9}\n",
      "0.969 (+/-0.071) for {'random_state': 10}\n",
      "1.000 (+/-0.000) for {'random_state': 11}\n",
      "0.969 (+/-0.071) for {'random_state': 12}\n",
      "0.969 (+/-0.071) for {'random_state': 13}\n",
      "0.969 (+/-0.071) for {'random_state': 14}\n",
      "0.969 (+/-0.071) for {'random_state': 15}\n",
      "1.000 (+/-0.000) for {'random_state': 16}\n",
      "0.984 (+/-0.059) for {'random_state': 17}\n",
      "0.984 (+/-0.059) for {'random_state': 18}\n",
      "1.000 (+/-0.000) for {'random_state': 19}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bon       0.96      0.96      0.96        23\n",
      "     Mauvais       0.00      0.00      0.00         0\n",
      "       Moyen       0.00      0.00      0.00         1\n",
      "    Médiocre       0.00      0.00      0.00         2\n",
      "    Très bon       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.86        28\n",
      "   macro avg       0.32      0.39      0.35        28\n",
      "weighted avg       0.83      0.86      0.84        28\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "print()\n",
    "\n",
    "tr = GridSearchCV(tree.DecisionTreeClassifier(), tree_param, cv=5,\n",
    "                   scoring='accuracy')\n",
    "tr.fit(Xss_train, Y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(tr.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = tr.cv_results_['mean_test_score']\n",
    "stds = tr.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, tr.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "Y_true, Y_pred = Y_test, tr.predict(Xss_test)\n",
    "print(metrics.classification_report(Y_true, Y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 5}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.734 (+/-0.248) for {'n_neighbors': 1}\n",
      "0.750 (+/-0.189) for {'n_neighbors': 2}\n",
      "0.797 (+/-0.303) for {'n_neighbors': 3}\n",
      "0.781 (+/-0.288) for {'n_neighbors': 4}\n",
      "0.812 (+/-0.319) for {'n_neighbors': 5}\n",
      "0.719 (+/-0.247) for {'n_neighbors': 6}\n",
      "0.812 (+/-0.190) for {'n_neighbors': 7}\n",
      "0.734 (+/-0.234) for {'n_neighbors': 8}\n",
      "0.766 (+/-0.229) for {'n_neighbors': 9}\n",
      "0.750 (+/-0.231) for {'n_neighbors': 10}\n",
      "0.766 (+/-0.258) for {'n_neighbors': 11}\n",
      "0.766 (+/-0.186) for {'n_neighbors': 12}\n",
      "0.781 (+/-0.178) for {'n_neighbors': 13}\n",
      "0.766 (+/-0.137) for {'n_neighbors': 14}\n",
      "0.766 (+/-0.137) for {'n_neighbors': 15}\n",
      "0.719 (+/-0.165) for {'n_neighbors': 16}\n",
      "0.734 (+/-0.146) for {'n_neighbors': 17}\n",
      "0.703 (+/-0.131) for {'n_neighbors': 18}\n",
      "0.703 (+/-0.131) for {'n_neighbors': 19}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bon       0.89      0.74      0.81        23\n",
      "     Mauvais       0.00      0.00      0.00         0\n",
      "       Moyen       0.00      0.00      0.00         1\n",
      "    Médiocre       0.00      0.00      0.00         2\n",
      "    Très bon       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.21      0.25      0.21        28\n",
      "weighted avg       0.75      0.64      0.68        28\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "print()\n",
    "\n",
    "knn = GridSearchCV(KNeighborsClassifier(), knn_param, cv=5,\n",
    "                   scoring='accuracy')\n",
    "knn.fit(Xss_train, Y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(knn.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = knn.cv_results_['mean_test_score']\n",
    "stds = knn.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, knn.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "Y_true, Y_pred = Y_test, knn.predict(Xss_test)\n",
    "print(metrics.classification_report(Y_true, Y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'tree CART': tree.DecisionTreeClassifier(random_state=0),\n",
    "    'MLP':MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(20, 10), random_state=1),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Bagging': BaggingClassifier(n_estimators=50, random_state=1),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=1),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'RF': RandomForestClassifier(n_estimators=50, random_state=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifiers(clfs, X, Y):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    result = {}\n",
    "\n",
    "    for i in clfs:\n",
    "        time_start = time.time()\n",
    "        clf = clfs[i]\n",
    "        \n",
    "        # calculer l'Accuracy par cross_val_score\n",
    "        cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "        \n",
    "        result.update({i: {'Accuracy': (np.mean(cv_acc), np.std(cv_acc)), \n",
    "                           'Execution time': (time.time() - time_start, 0.0)}\n",
    "                      })\n",
    "        \n",
    "    return result\n",
    "\n",
    "def print_results(results, ls_index):\n",
    "    for i in results.keys():\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(i)\n",
    "        print('------------------------------------------------------------------------')\n",
    "        for index in ls_index:\n",
    "            try:\n",
    "                print(\"{0}: {1:.3f} +/- {2:.3f}\".format(index, results[i][index][0], results[i][index][1]))\n",
    "            except:\n",
    "                print('<<< {0} >>> n\\'est pas dans liste: Accuracy, Execution time'.format(index))\n",
    "    #     print(\"AUC: {0:.3f} +/- {1:.3f}\".format(np.mean(aucs), np.std(aucs)))\n",
    "    #     print(\"Precision: {0:.3f} +/- {1:.3f}\".format(np.mean(cv_acc_2), np.std(cv_acc_2)))\n",
    "    #     print(\"Execution time: {0:.3f}s\".format(time.time() - time_start))\n",
    "        print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "GaussianNB\n",
      "------------------------------------------------------------------------\n",
      "Accuracy: 0.890 +/- 0.070\n",
      "Execution time: 0.039 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "tree CART\n",
      "------------------------------------------------------------------------\n",
      "Accuracy: 0.922 +/- 0.071\n",
      "Execution time: 0.021 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "MLP\n",
      "------------------------------------------------------------------------\n",
      "Accuracy: 0.944 +/- 0.075\n",
      "Execution time: 0.947 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "KNN\n",
      "------------------------------------------------------------------------\n",
      "Accuracy: 0.901 +/- 0.060\n",
      "Execution time: 0.021 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Bagging\n",
      "------------------------------------------------------------------------\n",
      "Accuracy: 0.944 +/- 0.056\n",
      "Execution time: 0.725 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "AdaBoost\n",
      "------------------------------------------------------------------------\n",
      "Accuracy: 0.933 +/- 0.054\n",
      "Execution time: 0.774 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "RF\n",
      "------------------------------------------------------------------------\n",
      "Accuracy: 0.901 +/- 0.060\n",
      "Execution time: 0.704 +/- 0.000\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = run_classifiers(clfs, X, Y)\n",
    "print_results(results, ['Accuracy', 'Execution time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose `Decision Tree` algorithm based on its accuracy and execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART's accuracy score:  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pip = Pipeline([('ss', StandardScaler()),\n",
    "                ('clf', tree.DecisionTreeClassifier(random_state=0))])\n",
    "pip.fit(X_train, Y_train)\n",
    "\n",
    "tree_score =  pip.score(X_test, Y_test)\n",
    "\n",
    "print('CART\\'s accuracy score: ',tree_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Demo a prediction with entered values of air quality index, temperature and humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bon'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([35, 291,  79])\n",
    "\n",
    "pip.predict(arr.reshape(1,-1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
